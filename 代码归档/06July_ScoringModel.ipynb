{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0da046-99df-42d7-9f48-6bef88fa52d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n基于PointNet++的牙预备体评分模型。\\n模型的输入为：若干预备体的点云和评分。\\n输出为：训练好的神经网络，可用于对新预备体点云评分。\\n目前在使用train on batch方法训练，在运算速度方面尚有优化余地。\\n\\n如果要在输入中加入预备前完整牙齿的图像，用算量更大的体素模型更为自然，但需要彻底另写程序（我知道得太晚了）。\\n点云模型是从预备体外表面上的采样点提取特征，而体素模型是把预备体扩充为一个三维矩阵，用这个矩阵提取特征；显然点云方法数据量更小。\\n如果同时输入完整牙齿和预备体的图像，体素方法可以在同一个矩阵格子里（同一个空间坐标）用两个值分别表示完整牙齿和预备体是否出现；\\n点云方法则不能在同一个坐标处同时给出完整牙齿和预备体的特征，需要单独为完整牙齿准备一套采样点。\\n考虑到完整牙齿和预备体的对比确实也可能包含一部分评分依据的信息，我们暂时保留同时输入这两种图像的思路。\\n\\n实际应用时，向训练集录入数据需要经过专家的监督，随后数据上传至总机。\\n模型的训练可以只会发生在官方的总机上。各地分机只需要读取稳定版模型参数，不必独自训练模型。\\n这也就是说，训练模型所需的计算只需要总机承担，分机的性能不需要很高。\\n如果没有即时更新数据库的需求，实际上总机的性能也不需要很高。\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "基于PointNet++的牙预备体评分模型。\n",
    "模型的输入为：若干预备体的点云和评分。\n",
    "输出为：训练好的神经网络，可用于对新预备体点云评分。\n",
    "目前在使用train on batch方法训练，在运算速度方面尚有优化余地。\n",
    "\n",
    "如果要在输入中加入预备前完整牙齿的图像，用算量更大的体素模型更为自然，但需要彻底另写程序（我知道得太晚了）。\n",
    "点云模型是从预备体外表面上的采样点提取特征，而体素模型是把预备体扩充为一个三维矩阵，用这个矩阵提取特征；显然点云方法数据量更小。\n",
    "如果同时输入完整牙齿和预备体的图像，体素方法可以在同一个矩阵格子里（同一个空间坐标）用两个值分别表示完整牙齿和预备体是否出现；\n",
    "点云方法则不能在同一个坐标处同时给出完整牙齿和预备体的特征，需要单独为完整牙齿准备一套采样点。\n",
    "考虑到完整牙齿和预备体的对比确实也可能包含一部分评分依据的信息，我们暂时保留同时输入这两种图像的思路。\n",
    "\n",
    "实际应用时，向训练集录入数据需要经过专家的监督，随后数据上传至总机。\n",
    "模型的训练可以只会发生在官方的总机上。各地分机只需要读取稳定版模型参数，不必独自训练模型。\n",
    "这也就是说，训练模型所需的计算只需要总机承担，分机的性能不需要很高。\n",
    "如果没有即时更新数据库的需求，实际上总机的性能也不需要很高。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc12696-3126-4a60-af32-034629428949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 安装环境，和上次发的代码一样的操作方式\\n!pip install --upgrade tensorflow\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 安装环境，和上次发的代码一样的操作方式\n",
    "!pip install --upgrade tensorflow\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9b0783-10e6-4622-9020-02da121f646d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 更新环境，以解决numpy和tensorflow的兼容性问题\\npip install --upgrade numpy tensorflow\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 更新环境，以解决numpy和tensorflow的兼容性问题\n",
    "pip install --upgrade numpy tensorflow\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867d9a15-d24e-448d-b536-5d4b10336a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 02:27:14.076762: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-07 02:27:14.080949: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-07 02:27:14.093870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-07 02:27:14.118850: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-07 02:27:14.118883: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-07 02:27:14.135178: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-07 02:27:15.028951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jupyter-24143/.local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c059d443-cbf9-4641-9d2f-ba3be8f622e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载输入信息\n",
    "\n",
    "def read_scores(score_file_path):\n",
    "    # 读全部牙的序号和评分\n",
    "    indices = []\n",
    "    scores = []\n",
    "    with open(score_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            index, score = line.strip().split()\n",
    "            indices.append(int(index))\n",
    "            scores.append(float(score))\n",
    "    return indices, scores\n",
    "\n",
    "def read_obj_file(obj_file_path):\n",
    "    # 读单颗牙的3D模型\n",
    "    points = []\n",
    "    with open(obj_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('v '):\n",
    "                _, x, y, z = line.strip().split()\n",
    "                points.append([float(x), float(y), float(z)])\n",
    "    return np.array(points)\n",
    "\n",
    "def sample_points(points, num_samples):\n",
    "    # 采样\n",
    "    # 由于每颗牙的3D模型顶点数不同（约2100+），不方便直接用作神经网络的输入，需要统一输入的格式\n",
    "    # 如果某颗牙的顶点数大于采样点数，则采样不可重复，否则采样可重复\n",
    "    # 为了和vertices做变量名上的区分，这个函数中使用了points这个变量名，但实际上就是vertices的数据\n",
    "    # 此处使用的是点云模型，如果用体素模型则有其他的配套手段\n",
    "    if len(points) >= num_samples:\n",
    "        # 如果点云中的点数大于等于采样点数，先进行非重复抽样\n",
    "        sampled_indices = np.random.choice(len(points), num_samples, replace=False)\n",
    "        sampled_points = points[sampled_indices]\n",
    "    else:\n",
    "        # 如果点云中的点数少于采样点数，先取所有的点，再进行可重复抽样补足数量\n",
    "        sampled_points = points.copy()\n",
    "        additional_samples = points[np.random.choice(len(points), num_samples - len(sampled_points), replace=True)]\n",
    "        sampled_points = np.concatenate((sampled_points, additional_samples), axis=0)\n",
    "    \n",
    "    return sampled_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab96a9e-e2cc-40b0-af99-65a94b9073bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Abstraction模块，用于提取点云的局部特征\n",
    "# 相较05July版本，用class重写了每个层\n",
    "# 已经能用测试数据无报错运行全部代码\n",
    "\n",
    "# 定义Sampling层\n",
    "class SamplingLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    最远点采样 Farthest Point Sample，通过“让采样点之间的最小距离最大化”来用尽可能少的点代表尽可能多的特征。\n",
    "    \n",
    "    算法是：\n",
    "        （1）先随机选取一个点，计算其余点到这个点的距离，选取距离最大的点做第二个点；\n",
    "        （2）已采样n个点时，计算所有剩余点到每个已采样点的距离，对单个剩余点总有一个已采样点在采样点中距离此剩余点最近，取前述最近距离最大的剩余点做为第n+1个采样点；\n",
    "        （3）重复此过程直至达到采样数目要求。\n",
    "    \n",
    "    输入是：\n",
    "        点云（每个点的前三个维度是其空间坐标，其余维度是特征）、采样数。\n",
    "    输出是：\n",
    "        采样出的点云（空间坐标维度+特征维度）。\n",
    "    '''\n",
    "    def __init__(self, N_prime, **kwargs):\n",
    "        super(SamplingLayer, self).__init__(**kwargs)\n",
    "        self.N_prime = N_prime\n",
    "\n",
    "    def call(self, points):\n",
    "        # 确认点数和采样数\n",
    "        B = tf.shape(points)[0]  # 获取批次大小\n",
    "        N = tf.shape(points)[1]  # 获取点的数量\n",
    "        # 初始化返回的采样点列表\n",
    "        sampled_points_batch = []\n",
    "        \n",
    "        # 遍历每个batch中的点云\n",
    "        for b in range(B):\n",
    "            # 初始化距离数组，设置为一个较大的数值\n",
    "            distances = tf.ones((N,), dtype=tf.float32) * 1e10\n",
    "            # 初始化当前batch的采样点列表\n",
    "            sampled_points = []\n",
    "\n",
    "            # 随机选择第一个点\n",
    "            first_point_index = tf.random.uniform(shape=[], minval=0, maxval=N, dtype=tf.int32)\n",
    "            first_point = tf.expand_dims(tf.gather(points[b], first_point_index, axis=0), axis=0)\n",
    "            sampled_points.append(first_point)\n",
    "\n",
    "            # 更新所有点到第一个采样点的距离，只考虑前三个特征维度作为空间坐标\n",
    "            distances = tf.norm(points[b, :, :3] - tf.expand_dims(points[b, first_point_index, :3], axis=0), axis=-1)\n",
    "\n",
    "            for i in range(1, self.N_prime):\n",
    "                # 选择距离当前所有采样点最远的点\n",
    "                farthest_point_index = tf.argmax(distances)\n",
    "                farthest_point = tf.expand_dims(tf.gather(points[b], farthest_point_index, axis=0), axis=0)\n",
    "                sampled_points.append(farthest_point)\n",
    "                \n",
    "                # 更新所有点到新加入的采样点的距离，只考虑前三个维度作为空间坐标\n",
    "                distances = tf.minimum(distances, tf.norm(points[b, :, :3] - tf.expand_dims(points[b, farthest_point_index, :3], axis=0), axis=-1))\n",
    "\n",
    "            # 将当前batch的采样点列表转换为张量，并添加到batch维度的列表中\n",
    "            sampled_points_batch.append(tf.concat(sampled_points, axis=0))\n",
    "\n",
    "        return tf.stack(sampled_points_batch, axis=0)  # 将采样点列表输出为张量\n",
    "    \n",
    "\n",
    "# 定义Grouping层\n",
    "class GroupingLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    Ball query，以FPS采样结果的每个点为球心，找到采样前总点云中距离每个球心最近的K个点（含球心），以便在后续步骤中提取局部特征。\n",
    "    \n",
    "    算法是：\n",
    "        （1）预设搜索区域的半径R与子区域的点数K；\n",
    "        （2）FPS采样函数已经提取出来了N'个点，以这N'个点为球心，画半径为R的球体（叫做query ball，也就是搜索区域）；\n",
    "        （3）以每个样本点为球心，按照给定搜索半径R得到一个球形搜索区域，然后从该区域提取前K个最邻近点。如果搜索区域内点数不够，则重复采样；\n",
    "        （4）得到N'个采样点各自对应的包含K个点的子区域，这是一个N'*K*（空间维度+特征维度）的点云。\n",
    "    \n",
    "    输入是：\n",
    "        FPS采样前的点云、FPS采样后的点云、搜索半径R、子区域点数K。\n",
    "    输出是：\n",
    "        N'个采样点各自对应的包含K个点的子区域点云。\n",
    "    '''\n",
    "    def __init__(self, R, K, **kwargs):\n",
    "        super(GroupingLayer, self).__init__(**kwargs)\n",
    "        self.R = R\n",
    "        self.K = K\n",
    "\n",
    "    def call(self, sampled_points, points):\n",
    "        # 读输入点云形状\n",
    "        B, N_prime, D = sampled_points.shape\n",
    "        B, N, D = points.shape\n",
    "\n",
    "        # 初始化返回的全部子区域点云列表\n",
    "        local_regions = []\n",
    "\n",
    "        for b in range(B):\n",
    "            # 初始化当前batch的子区域点云列表\n",
    "            local_region_b = []\n",
    "\n",
    "            for i in range(N_prime):\n",
    "                # 获取当前球心坐标\n",
    "                center_point = sampled_points[b, i]\n",
    "                # 计算所有点到球心的距离\n",
    "                distances = tf.norm(points[b, :, :3] - tf.expand_dims(center_point[:3], axis=0), axis=-1)\n",
    "                # 找到半径R内的点的索引\n",
    "                within_radius_indices = tf.where(distances <= self.R)[:, 0]\n",
    "                # 找到半径R内点的数量\n",
    "                num_within_radius = tf.size(within_radius_indices)\n",
    "                \n",
    "                # 如果半径R内点的数量少于K个，则随机采样补充至K个\n",
    "                nearest_indices = tf.cond(\n",
    "                    num_within_radius < self.K,\n",
    "                    # if分支，先按距离升序给所有点排序并保留全部点，随后用有放回抽样补足K个点数\n",
    "                    lambda: tf.concat(\n",
    "                        [\n",
    "                            tf.gather(within_radius_indices, tf.argsort(tf.gather(distances, within_radius_indices))), \n",
    "                            tf.gather(within_radius_indices, tf.random.uniform(\n",
    "                                shape=[self.K - num_within_radius], \n",
    "                                minval=0, \n",
    "                                maxval=num_within_radius, \n",
    "                                dtype=tf.int32)\n",
    "                            )\n",
    "                        ], \n",
    "                        axis=0\n",
    "                    )[:self.K],\n",
    "                    # else分支，先按距离升序给所有点排序，然后取前K个\n",
    "                    lambda: tf.gather(within_radius_indices, tf.argsort(tf.gather(distances, within_radius_indices))[:self.K])\n",
    "                )\n",
    "\n",
    "                # 确保nearest_indices的形状为(K,)\n",
    "                nearest_indices = tf.reshape(nearest_indices, (self.K,))  # 调试时这里的K总是变成NoneType占位符，所以这里要强制固定其格式\n",
    "\n",
    "                # 将该球心的子区域点云列表转为张量形式，并保存\n",
    "                local_region = tf.gather(points[b], nearest_indices, axis=0)\n",
    "                local_region_b.append(local_region)\n",
    "\n",
    "            # 保存返回的全部子区域点云列表\n",
    "            local_regions.append(tf.stack(local_region_b, axis=0))\n",
    "\n",
    "        return tf.stack(local_regions, axis=0)  # 将全部子区域点云列表输出为张量\n",
    "\n",
    "\n",
    "# 定义PointNEt层\n",
    "class PointNetLayer(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    PointNet卷积层，用卷积对采样点进行局部特征提取。\n",
    "    \n",
    "    算法是：\n",
    "        （1）使用局部坐标来抗平移、旋转；\n",
    "        （2）多层感知机（MLP）* 1维卷积。\n",
    "    \n",
    "    输入是：\n",
    "        Ball query得到的N'个采样点各自对应的包含K个点的子区域点云。\n",
    "    输出是：\n",
    "        包含新特征的点云（形状是B*N'*(3+新特征数量)）\n",
    "    '''\n",
    "    def __init__(self, conv_layers, **kwargs):\n",
    "        super(PointNetLayer, self).__init__(**kwargs)\n",
    "        # 传入\n",
    "        self.conv_layers = conv_layers\n",
    "\n",
    "    def call(self, local_regions):\n",
    "        B, N_prime, K, D = tf.unstack(tf.shape(local_regions))\n",
    "        \n",
    "        # 计算局部坐标，即令每个局部区域的所有点的坐标减掉该区域的球心坐标\n",
    "        center_point = local_regions[:, :, 0, :3]  # Shape: (B, N', 3)\n",
    "        local_coords = local_regions[:, :, :, :3] - tf.expand_dims(center_point, axis=2)\n",
    "        \n",
    "        # 把局部坐标（前3个特征维度）和特征（后续特征维度）拼接到一起\n",
    "        reshape_points = tf.concat([local_coords, local_regions[:, :, :, 3:]], axis=-1)\n",
    "        \n",
    "        # 将局部区域点云变形为 (B, N', K * D) 的形状，并转换为 float32 类型，便于进行卷积运算\n",
    "        reshape_points = tf.reshape(reshape_points, (B, N_prime, K * D))\n",
    "        reshape_points = tf.cast(reshape_points, dtype=tf.float32)\n",
    "\n",
    "        # 用1维卷积做特征提取。\n",
    "        # 注意，不同于传统2维卷积的功能，1维卷积只能将同一点的不同特征做混合，不能提取几何形状（即不同点相对位置）中的特征。\n",
    "        # 提取几何形状特征是靠前面两层即对点云的采样和分组实现的。\n",
    "        new_points = reshape_points\n",
    "        for layer in self.conv_layers:\n",
    "            # MLP和卷积运算，参数来自传入\n",
    "            new_points = layer(new_points)\n",
    "        \n",
    "        # 将原始点的坐标与提取的特征拼接\n",
    "        new_points = tf.concat([center_point, new_points], axis=-1)\n",
    "        \n",
    "        return new_points\n",
    "\n",
    "\n",
    "# 定义完整SA模块\n",
    "class SAModule(tf.keras.layers.Layer):\n",
    "    '''\n",
    "    完整的Set Abstraction模块，由Sampling层、Grouping层、PointNet层串联组成。\n",
    "    '''\n",
    "    def __init__(self, sampling_layer, grouping_layer, pointnet_layer, **kwargs):\n",
    "        super(SAModule, self).__init__(**kwargs)\n",
    "        self.sampling_layer = sampling_layer\n",
    "        self.grouping_layer = grouping_layer\n",
    "        self.pointnet_layer = pointnet_layer\n",
    "\n",
    "    def call(self, points):\n",
    "        # 所有print都是为了显示中间结果，便于调试，正式版本会删除它们\n",
    "        sampled_points = self.sampling_layer(points)\n",
    "        # print(f\"SamplingLayer output shape: {sampled_points.shape}\")\n",
    "        grouped_points = self.grouping_layer(sampled_points, points)\n",
    "        # print(f\"GroupingLayer output shape: {grouped_points.shape}\")\n",
    "        new_points = self.pointnet_layer(grouped_points)\n",
    "        # print(f\"PointNetLayer output shape: {new_points.shape}\")\n",
    "        return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3224a78-a1fc-43ec-81bf-71a46807ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义完整神经网络\n",
    "\n",
    "class PointNetPlusPlus(tf.keras.Model):\n",
    "    def __init__(self, input_shape, **kwargs):\n",
    "        super(PointNetPlusPlus, self).__init__(**kwargs)\n",
    "        # 三个采样和特征提取层，其中第三层不做采样。需调用SA模块\n",
    "        self.block1 = SAModule(\n",
    "            SamplingLayer(N_prime=256),\n",
    "            GroupingLayer(R=5, K=10),\n",
    "            PointNetLayer(conv_layers=[layers.Conv1D(64, 1, activation='relu'),\n",
    "                                       layers.Conv1D(64, 1, activation='relu'),\n",
    "                                       layers.Conv1D(128, 1, activation='relu')])\n",
    "        )\n",
    "        self.block2 = SAModule(\n",
    "            SamplingLayer(N_prime=128),\n",
    "            GroupingLayer(R=5, K=8),\n",
    "            PointNetLayer(conv_layers=[layers.Conv1D(128, 1, activation='relu'),\n",
    "                                       layers.Conv1D(128, 1, activation='relu'),\n",
    "                                       layers.Conv1D(256, 1, activation='relu')])\n",
    "        )\n",
    "        self.block3 = SAModule(\n",
    "            SamplingLayer(N_prime=64),\n",
    "            GroupingLayer(R=5, K=8),\n",
    "            PointNetLayer(conv_layers=[layers.Conv1D(256, 1, activation='relu'),\n",
    "                                       layers.Conv1D(256, 1, activation='relu'),\n",
    "                                       layers.Conv1D(512, 1, activation='relu')])\n",
    "        )\n",
    "        # 全局最大池化层，用于压缩数据量，也实现了数据扁平化\n",
    "        self.global_feature_layer = layers.GlobalAveragePooling1D()\n",
    "        # 全连接层和Dropout层，前者用于进行特征的整合和最终的输出，后者用于减少神经网络的过拟合\n",
    "        self.dense1 = layers.Dense(256, activation='relu')\n",
    "        self.dropout1 = layers.Dropout(0.5)\n",
    "        self.dense2 = layers.Dense(128, activation='relu')\n",
    "        self.dropout2 = layers.Dropout(0.5)\n",
    "        # 输出层\n",
    "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        #输入层\n",
    "        points = inputs\n",
    "        # 三个采样和特征提取层，其中第三层不做采样。需调用SA模块\n",
    "        points = self.block1(points)\n",
    "        points = self.block2(points)\n",
    "        points = self.block3(points)\n",
    "        # 全局最大池化层，用于压缩数据量，也实现了数据扁平化\n",
    "        global_features = self.global_feature_layer(points)\n",
    "        # 全连接层和Dropout层，前者用于进行特征的整合和最终的输出，后者用于减少神经网络的过拟合\n",
    "        x = self.dense1(global_features)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "        # 输出层\n",
    "        output = self.output_layer(x)\n",
    "        return output\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(PointNetPlusPlus, self).get_config()\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(input_shape=config['input_shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523cf7cb-814c-4816-ab15-d9a928a7c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读序号和评分\n",
    "'''此处为text文件地址，应当改为：’文件夹路径 + scores.txt'''\n",
    "score_file_path = 'scores.txt'\n",
    "indices, scores = read_scores(score_file_path)\n",
    "\n",
    "# 读3D模型，并完成采样\n",
    "'''设置采样点数'''\n",
    "num_samples = 2000 \n",
    "Vertices = []\n",
    "for i in indices:\n",
    "    obj_file_path = f'{i}.obj'  # 此处为obj文件地址，应当改为：f’ + 文件夹路径 + {i}.obj\n",
    "    points = read_obj_file(obj_file_path)\n",
    "    sampled_points = sample_points(points, num_samples)\n",
    "    Vertices.append(sampled_points)\n",
    "Vertices = np.array(Vertices)\n",
    "Scores = np.array(scores)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "'''此处用的4：1随机分配，以后可以改成k折'''\n",
    "Vertices_train, Vertices_test, Scores_train, Scores_test = train_test_split(Vertices, Scores, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4cba0d6-228a-4b4c-9f9c-c89aadf24298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Training Loss: 4561.5655517578125\n",
      "Epoch 2/3\n",
      "Training Loss: 4557.3916422526045\n",
      "Epoch 3/3\n",
      "Training Loss: 4557.3916422526045\n",
      "Test Loss: 5065.10009765625\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "model = PointNetPlusPlus(input_shape=(num_samples, 3))\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# 定义批量大小和训练迭代次数\n",
    "batch_size = 10\n",
    "epochs = 3\n",
    "\n",
    "# 手动实现批量训练（Train on batch），如果用fit就会出现“静态计算图”、“B = None”等问题，暂且绕过\n",
    "num_batches_train = len(Vertices_train) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    epoch_loss = 0.0\n",
    "    for batch in range(num_batches_train):\n",
    "        start_idx = batch * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_vertices = Vertices_train[start_idx:end_idx]\n",
    "        batch_scores = Scores_train[start_idx:end_idx]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(batch_vertices, training=True)\n",
    "            loss = loss_fn(batch_scores, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "    print(f\"Training Loss: {epoch_loss / num_batches_train}\")\n",
    "\n",
    "# 模型评估\n",
    "predictions_test = model(Vertices_test, training=False)\n",
    "test_loss = loss_fn(Scores_test, predictions_test).numpy()\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9589ffdf-7ff9-4909-a4eb-c98cd765731c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型配置和权重保存成功。\n"
     ]
    }
   ],
   "source": [
    "# 保存模型权重\n",
    "model.save_weights('model_weights.weights.h5')\n",
    "\n",
    "# 保存模型配置\n",
    "model_config = {\n",
    "    'input_shape': (num_samples, 3)  # 根据你的模型定义调整\n",
    "}\n",
    "with open('model_config.json', 'w') as f:\n",
    "    json.dump(model_config, f)\n",
    "\n",
    "print(\"模型配置和权重保存成功。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fbb6b0e-5ffb-44e7-afb1-edf79243dd73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载成功。\n"
     ]
    }
   ],
   "source": [
    "# 加载模型配置\n",
    "with open('model_config.json', 'r') as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "# 定义模型\n",
    "model = PointNetPlusPlus(**model_config)\n",
    "\n",
    "# 加载模型权重\n",
    "model.load_weights('model_weights.weights.h5')\n",
    "\n",
    "print(\"模型加载成功。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b85c24de-d1ed-4fe3-b22a-c9798881b4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置采样点数\n",
    "num_samples = 2000\n",
    "\n",
    "# 读取和采样点云数据\n",
    "obj_file_path = '22.obj'\n",
    "points = read_obj_file(obj_file_path)\n",
    "sampled_points = sample_points(points, num_samples)\n",
    "sampled_points = np.expand_dims(sampled_points, axis=0)  # 扩展维度以匹配模型输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d390e205-6b50-484b-a0dc-a39a2e04ce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测评分: 0.11882804334163666\n"
     ]
    }
   ],
   "source": [
    "# 使用模型进行预测\n",
    "prediction = model(sampled_points, training=False)\n",
    "score = prediction.numpy()[0][0]\n",
    "\n",
    "print(f\"预测评分: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58273b9-45d6-486d-91e4-8e2ee310b4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacabf9c-578c-48ed-afa8-7d893a4a3c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
