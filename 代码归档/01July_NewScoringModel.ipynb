{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c5af2e2-e3cc-4d15-848f-dd7d6fa720e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n基于PointNet++的CNN模型，这个是基础版。\\n输入是点云和评分，输出是训练好的神经网络，可用于对新点云评分。\\n如果接受更大的算量，接下来还可以试一下体素模型（把输入端的点云采样改为体素，前者是从n个点里选m个，后者是把n个点扩展为N个，除此之外算法也要重写）。\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "基于PointNet++的CNN模型框架，一些细节并不正确。\n",
    "输入是点云和评分，输出是训练好的神经网络，可用于对新点云评分。\n",
    "如果接受更大的算量，接下来还可以试一下体素模型（把输入端的点云采样改为体素，前者是从n个点里选m个，后者是把n个点扩展为N个，除此之外算法也要重写）。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b3ee96-28c3-495f-bb72-f598dde62daf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 安装环境，和上次发的代码一样的操作方式\\n!pip install --upgrade tensorflow\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 安装环境，和上次发的代码一样的操作方式\n",
    "!pip install --upgrade tensorflow\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a262ab-4376-4263-a0fb-00e1933f52fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 更新环境，以解决numpy和tensorflow的兼容性问题\\npip install --upgrade numpy tensorflow\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 更新环境，以解决numpy和tensorflow的兼容性问题\n",
    "pip install --upgrade numpy tensorflow\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2255fe5b-5bb5-4855-8500-84c2ac37884c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 23:16:24.045229: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 23:16:24.049545: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-02 23:16:24.063277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 23:16:24.170915: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 23:16:24.170988: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 23:16:24.191362: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-02 23:16:25.207986: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jupyter-24143/.local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bada35a-b460-48ae-84ee-1c47e6a789d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_scores(file_path):\n",
    "    # 读全部牙的序号和评分\n",
    "    indices = []\n",
    "    scores = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 2:\n",
    "                try:\n",
    "                    index = int(parts[0])\n",
    "                    score = float(parts[1])\n",
    "                    indices.append(index)\n",
    "                    scores.append(score)\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping line due to value error: {line.strip()}\")\n",
    "            else:\n",
    "                print(f\"Skipping line due to incorrect format: {line.strip()}\")\n",
    "    return indices, scores\n",
    "\n",
    "def read_obj_file(file_path):\n",
    "    # 读单颗牙的3D模型\n",
    "    vertices = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('v '):\n",
    "                parts = line.strip().split()\n",
    "                vertex = list(map(float, parts[1:4]))\n",
    "                vertices.append(vertex)\n",
    "    return np.array(vertices)\n",
    "\n",
    "def sample_points(points, num_samples):\n",
    "    # 采样\n",
    "    # 由于每颗牙的3D模型顶点数不同（约2100+），不方便直接用作神经网络的输入，需要统一输入的格式\n",
    "    # 如果某颗牙的顶点数大于采样点数，则采样不可重复，否则采样可重复\n",
    "    # 为了和vertices做变量名上的区分，这个函数中使用了points这个变量名，但实际上就是vertices的数据\n",
    "    # 此处使用的是点云模型，如果用体素模型则有其他的配套手段\n",
    "    if len(points) >= num_samples:\n",
    "        sampled_points = points[np.random.choice(len(points), num_samples, replace=False)]\n",
    "    else:\n",
    "        sampled_points = points[np.random.choice(len(points), num_samples, replace=True)]\n",
    "    return sampled_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e00375-b145-4a0b-a948-6f5df64428c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PointNet++模型\n",
    "\n",
    "def pointnet_sa_module(xyz, npoint, mlp):\n",
    "    '''\n",
    "    Set Abstraction模块，用于提取点云的局部特征\n",
    "    其输入为：\n",
    "    xyz = 输入点云的3维坐标xzy\n",
    "    npoint = 采样点数\n",
    "    mlp = 多层感知机(Multilayer Perceptron)每层神经元数量的列表\n",
    "    其输出为：\n",
    "    采样后的点云new_xyz，形状为npoint*3\n",
    "    提取到的特征new_points，形状为npoints*out_channel，也就是点数不变但维数变为多层感知机最后一层的节点数\n",
    "    '''\n",
    "    # 采样点云的前 npoint 个点，可以压缩数据量，也可以令每颗牙的数据尺寸一致化\n",
    "    '''！！！这里有问题！！！'''\n",
    "    new_xyz = xyz[:npoint, :]\n",
    "    \n",
    "    # 用1维卷积做特征提取\n",
    "    # 1维卷积只能将同一点的不同特征做混合，不同点相对位置引起的特征是靠对点云的采样和分组实现的\n",
    "    new_points = new_xyz\n",
    "    for out_channel in mlp:\n",
    "        new_points = layers.Conv1D(out_channel, 1, activation='relu')(new_points)\n",
    "    return new_xyz, new_points\n",
    "\n",
    "def build_pointnetplusplus(input_shape):\n",
    "    '''\n",
    "    PointNet++模型，需要调用SA模块\n",
    "    输入为“单颗牙的3D模型在采样后的数据格式”，即num_samples*3\n",
    "    输出为训练好的模型\n",
    "    '''\n",
    "    #输入层\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    l0_xyz = inputs\n",
    "    \n",
    "    # 三个采样和特征提取层，其中第三层不做采样。需调用SA模块\n",
    "    l1_xyz, l1_points = pointnet_sa_module(l0_xyz, npoint=512, mlp=[64, 64, 128])\n",
    "    l2_xyz, l2_points = pointnet_sa_module(l1_xyz, npoint=128, mlp=[128, 128, 256])\n",
    "    l3_xyz, l3_points = pointnet_sa_module(l2_xyz, npoint=None, mlp=[256, 512, 1024])\n",
    "    \n",
    "    # 全局最大池化层，用于压缩数据量，也实现了数据扁平化\n",
    "    x = layers.GlobalMaxPooling1D()(l3_points)\n",
    "    \n",
    "    # 全连接层和Dropout层，前者用于进行特征的整合和最终的输出，后者用于减少神经网络的过拟合\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # 输出层\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    \n",
    "    # 构建模型\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    '''\n",
    "    编译模型：\n",
    "    Adam优化器用于加快训练\n",
    "    均方误差Mean Squared Error作为损失函数\n",
    "    平均绝对误差Mean Absolute Error作为评价指标\n",
    "    '''\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5905a59-7225-48e0-806e-fbfff0dfefc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读序号和评分\n",
    "'''此处为text文件地址，应当改为：’文件夹路径 + scores.txt'''\n",
    "score_file_path = 'scores.txt'\n",
    "indices, scores = read_scores(score_file_path)\n",
    "\n",
    "# 读3D模型，并完成采样\n",
    "'''设置采样点数为1024，可修改'''\n",
    "num_samples = 1024  \n",
    "Vertices = []\n",
    "for i in indices:\n",
    "    obj_file_path = f'{i}.obj'  # 此处为obj文件地址，应当改为：f’ + 文件夹路径 + {i}.obj\n",
    "    points = read_obj_file(obj_file_path)\n",
    "    sampled_points = sample_points(points, num_samples)\n",
    "    Vertices.append(sampled_points)\n",
    "Vertices = np.array(Vertices)\n",
    "Scores = np.array(scores)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "'''此处用的4：1随机分配，以后可以改成k折'''\n",
    "Vertices_train, Vertices_test, Scores_train, Scores_test = train_test_split(Vertices, Scores, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06419d08-27b7-479e-a79b-2f61e72e8947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - loss: 2330.0386 - mae: 42.7014 - val_loss: 481.8236 - val_mae: 19.5795\n",
      "Epoch 2/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 562.5247 - mae: 17.6014 - val_loss: 477.5894 - val_mae: 18.7642\n",
      "Epoch 3/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 415.3473 - mae: 16.4173 - val_loss: 441.5332 - val_mae: 19.1154\n",
      "Epoch 4/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - loss: 403.6625 - mae: 16.9036 - val_loss: 355.3603 - val_mae: 15.9048\n",
      "Epoch 5/5\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2s/step - loss: 309.9753 - mae: 13.1624 - val_loss: 287.1973 - val_mae: 13.6874\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "model = build_pointnetplusplus((num_samples, 3))\n",
    "history = model.fit(Vertices_train, Scores_train, epochs=5, batch_size=8, validation_data=(Vertices_test, Scores_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1aa8f7f-515c-4f2a-aa0c-510de65c364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 287.1973 - mae: 13.6874\n",
      "Test Loss: 287.19732666015625\n",
      "Test MAE: 13.68735122680664\n"
     ]
    }
   ],
   "source": [
    "# 模型评价\n",
    "loss, mae = model.evaluate(Vertices_test, Scores_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d489a1-78e1-416c-80a9-2b5c69836a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save('saved_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ad53f9-0684-41e4-bbb1-44f8aae53e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "loaded_model = tf.keras.models.load_model('saved_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8cc04d-d03f-4ecb-88c0-acb140addee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    }
   ],
   "source": [
    "def evaluate(new_obj_file_path):\n",
    "    # 读取并预处理新OBJ文件\n",
    "    new_vertices = read_obj_file(new_obj_file_path)\n",
    "    new_sampled_points = sample_points(new_vertices, num_samples)\n",
    "    new_sampled_points = np.expand_dims(new_sampled_points, axis=0)  # 添加批次维度\n",
    "    \n",
    "    # 使用加载的模型进行预测\n",
    "    predicted_score = loaded_model.predict(new_sampled_points)\n",
    "    # print(\"Predicted Score:\", predicted_score[0])\n",
    "    \n",
    "    return predicted_score\n",
    "\n",
    "evaluate_result = {}\n",
    "for i in range(150):\n",
    "    new_obj_file_path = f'{i+1}.obj'  # 待评价对象的地址\n",
    "    evaluate_result[i] = evaluate(new_obj_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48c108e7-7b01-4d1f-bafc-1dd35c8869ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[64.92832]], dtype=float32),\n",
       " 1: array([[61.108406]], dtype=float32),\n",
       " 2: array([[61.335632]], dtype=float32),\n",
       " 3: array([[66.16812]], dtype=float32),\n",
       " 4: array([[62.129997]], dtype=float32),\n",
       " 5: array([[55.568108]], dtype=float32),\n",
       " 6: array([[55.61471]], dtype=float32),\n",
       " 7: array([[63.957825]], dtype=float32),\n",
       " 8: array([[61.437004]], dtype=float32),\n",
       " 9: array([[59.736763]], dtype=float32),\n",
       " 10: array([[66.75143]], dtype=float32),\n",
       " 11: array([[60.286205]], dtype=float32),\n",
       " 12: array([[62.081223]], dtype=float32),\n",
       " 13: array([[65.43191]], dtype=float32),\n",
       " 14: array([[62.682987]], dtype=float32),\n",
       " 15: array([[56.22727]], dtype=float32),\n",
       " 16: array([[57.138054]], dtype=float32),\n",
       " 17: array([[63.487835]], dtype=float32),\n",
       " 18: array([[62.372684]], dtype=float32),\n",
       " 19: array([[59.118942]], dtype=float32),\n",
       " 20: array([[66.669495]], dtype=float32),\n",
       " 21: array([[60.787827]], dtype=float32),\n",
       " 22: array([[60.803593]], dtype=float32),\n",
       " 23: array([[64.47334]], dtype=float32),\n",
       " 24: array([[61.262966]], dtype=float32),\n",
       " 25: array([[56.041462]], dtype=float32),\n",
       " 26: array([[55.680515]], dtype=float32),\n",
       " 27: array([[62.912933]], dtype=float32),\n",
       " 28: array([[62.492676]], dtype=float32),\n",
       " 29: array([[59.122375]], dtype=float32),\n",
       " 30: array([[66.37567]], dtype=float32),\n",
       " 31: array([[60.448902]], dtype=float32),\n",
       " 32: array([[61.032326]], dtype=float32),\n",
       " 33: array([[65.92119]], dtype=float32),\n",
       " 34: array([[60.805172]], dtype=float32),\n",
       " 35: array([[54.52429]], dtype=float32),\n",
       " 36: array([[54.941933]], dtype=float32),\n",
       " 37: array([[63.06832]], dtype=float32),\n",
       " 38: array([[62.630447]], dtype=float32),\n",
       " 39: array([[59.405975]], dtype=float32),\n",
       " 40: array([[66.43259]], dtype=float32),\n",
       " 41: array([[61.070114]], dtype=float32),\n",
       " 42: array([[62.048477]], dtype=float32),\n",
       " 43: array([[66.003235]], dtype=float32),\n",
       " 44: array([[61.216064]], dtype=float32),\n",
       " 45: array([[56.62683]], dtype=float32),\n",
       " 46: array([[55.42607]], dtype=float32),\n",
       " 47: array([[62.971886]], dtype=float32),\n",
       " 48: array([[62.760178]], dtype=float32),\n",
       " 49: array([[58.663498]], dtype=float32),\n",
       " 50: array([[66.21381]], dtype=float32),\n",
       " 51: array([[55.702583]], dtype=float32),\n",
       " 52: array([[57.54197]], dtype=float32),\n",
       " 53: array([[62.689903]], dtype=float32),\n",
       " 54: array([[59.36424]], dtype=float32),\n",
       " 55: array([[53.550587]], dtype=float32),\n",
       " 56: array([[53.290382]], dtype=float32),\n",
       " 57: array([[58.548462]], dtype=float32),\n",
       " 58: array([[59.59715]], dtype=float32),\n",
       " 59: array([[55.95093]], dtype=float32),\n",
       " 60: array([[63.191837]], dtype=float32),\n",
       " 61: array([[57.708733]], dtype=float32),\n",
       " 62: array([[58.454384]], dtype=float32),\n",
       " 63: array([[63.80396]], dtype=float32),\n",
       " 64: array([[59.882366]], dtype=float32),\n",
       " 65: array([[53.581093]], dtype=float32),\n",
       " 66: array([[51.07236]], dtype=float32),\n",
       " 67: array([[58.53646]], dtype=float32),\n",
       " 68: array([[58.76026]], dtype=float32),\n",
       " 69: array([[56.091896]], dtype=float32),\n",
       " 70: array([[63.53918]], dtype=float32),\n",
       " 71: array([[57.655293]], dtype=float32),\n",
       " 72: array([[59.58976]], dtype=float32),\n",
       " 73: array([[62.965477]], dtype=float32),\n",
       " 74: array([[59.42521]], dtype=float32),\n",
       " 75: array([[53.191433]], dtype=float32),\n",
       " 76: array([[52.390923]], dtype=float32),\n",
       " 77: array([[59.577557]], dtype=float32),\n",
       " 78: array([[59.735054]], dtype=float32),\n",
       " 79: array([[57.066452]], dtype=float32),\n",
       " 80: array([[63.577797]], dtype=float32),\n",
       " 81: array([[57.329624]], dtype=float32),\n",
       " 82: array([[59.540966]], dtype=float32),\n",
       " 83: array([[62.282356]], dtype=float32),\n",
       " 84: array([[55.620712]], dtype=float32),\n",
       " 85: array([[51.4383]], dtype=float32),\n",
       " 86: array([[52.608437]], dtype=float32),\n",
       " 87: array([[58.733738]], dtype=float32),\n",
       " 88: array([[58.69675]], dtype=float32),\n",
       " 89: array([[54.22326]], dtype=float32),\n",
       " 90: array([[63.51366]], dtype=float32),\n",
       " 91: array([[59.076786]], dtype=float32),\n",
       " 92: array([[59.83556]], dtype=float32),\n",
       " 93: array([[65.18282]], dtype=float32),\n",
       " 94: array([[65.51731]], dtype=float32),\n",
       " 95: array([[57.603027]], dtype=float32),\n",
       " 96: array([[56.120083]], dtype=float32),\n",
       " 97: array([[52.879936]], dtype=float32),\n",
       " 98: array([[61.486763]], dtype=float32),\n",
       " 99: array([[60.753395]], dtype=float32),\n",
       " 100: array([[76.73697]], dtype=float32),\n",
       " 101: array([[84.990715]], dtype=float32),\n",
       " 102: array([[80.095436]], dtype=float32),\n",
       " 103: array([[70.8484]], dtype=float32),\n",
       " 104: array([[81.8799]], dtype=float32),\n",
       " 105: array([[74.98679]], dtype=float32),\n",
       " 106: array([[67.749756]], dtype=float32),\n",
       " 107: array([[75.52355]], dtype=float32),\n",
       " 108: array([[83.62322]], dtype=float32),\n",
       " 109: array([[79.45399]], dtype=float32),\n",
       " 110: array([[71.46573]], dtype=float32),\n",
       " 111: array([[63.859093]], dtype=float32),\n",
       " 112: array([[60.143864]], dtype=float32),\n",
       " 113: array([[63.45227]], dtype=float32),\n",
       " 114: array([[66.01265]], dtype=float32),\n",
       " 115: array([[63.594803]], dtype=float32),\n",
       " 116: array([[57.371994]], dtype=float32),\n",
       " 117: array([[63.71904]], dtype=float32),\n",
       " 118: array([[63.42391]], dtype=float32),\n",
       " 119: array([[61.485165]], dtype=float32),\n",
       " 120: array([[71.08995]], dtype=float32),\n",
       " 121: array([[63.13942]], dtype=float32),\n",
       " 122: array([[58.953476]], dtype=float32),\n",
       " 123: array([[61.61844]], dtype=float32),\n",
       " 124: array([[64.45422]], dtype=float32),\n",
       " 125: array([[61.98976]], dtype=float32),\n",
       " 126: array([[56.797165]], dtype=float32),\n",
       " 127: array([[63.886257]], dtype=float32),\n",
       " 128: array([[62.242233]], dtype=float32),\n",
       " 129: array([[60.662037]], dtype=float32),\n",
       " 130: array([[77.45217]], dtype=float32),\n",
       " 131: array([[86.1311]], dtype=float32),\n",
       " 132: array([[71.73287]], dtype=float32),\n",
       " 133: array([[82.13662]], dtype=float32),\n",
       " 134: array([[84.214516]], dtype=float32),\n",
       " 135: array([[75.90889]], dtype=float32),\n",
       " 136: array([[69.80891]], dtype=float32),\n",
       " 137: array([[76.466995]], dtype=float32),\n",
       " 138: array([[86.3309]], dtype=float32),\n",
       " 139: array([[71.66991]], dtype=float32),\n",
       " 140: array([[81.40974]], dtype=float32),\n",
       " 141: array([[83.32239]], dtype=float32),\n",
       " 142: array([[75.79213]], dtype=float32),\n",
       " 143: array([[69.28582]], dtype=float32),\n",
       " 144: array([[77.28111]], dtype=float32),\n",
       " 145: array([[85.280685]], dtype=float32),\n",
       " 146: array([[71.71799]], dtype=float32),\n",
       " 147: array([[84.148895]], dtype=float32),\n",
       " 148: array([[74.9666]], dtype=float32),\n",
       " 149: array([[70.04513]], dtype=float32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
