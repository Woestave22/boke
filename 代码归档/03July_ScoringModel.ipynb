{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ff708b-4a3d-4c48-95e1-9ffc5e694666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n基于PointNet++的CNN模型，能够实现基本功能。没有为提高运算效率而牺牲可读性，包会。\\n输入是预备体的点云和评分，输出是训练好的神经网络，可用于对新预备体点云评分。\\n尚有优化余地。此外，接下来还可以试一下算量更大的体素模型，那个模型便于同时输入真牙和预备体的图像。\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "基于PointNet++的CNN模型，未完成batch维度。\n",
    "输入是预备体的点云和评分，输出是训练好的神经网络，可用于对新预备体点云评分。\n",
    "尚有优化余地。此外，接下来还可以试一下算量更大的体素模型，那个模型便于同时输入真牙和预备体的图像。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f349cb-60a9-475d-b412-bae48c64d941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 安装环境，和上次发的代码一样的操作方式\\n!pip install --upgrade tensorflow\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 安装环境，和上次发的代码一样的操作方式\n",
    "!pip install --upgrade tensorflow\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e29e618-d1f1-4224-b329-03e0b0a7bb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 更新环境，以解决numpy和tensorflow的兼容性问题\\npip install --upgrade numpy tensorflow\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 更新环境，以解决numpy和tensorflow的兼容性问题\n",
    "pip install --upgrade numpy tensorflow\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5acca15e-204f-4df6-b947-05280e32dae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 10:02:35.193634: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-04 10:02:35.200825: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-04 10:02:35.215514: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-04 10:02:35.251579: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-04 10:02:35.251627: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-04 10:02:35.276037: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-04 10:02:36.500916: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jupyter-24143/.local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27fd7e58-4abd-40d5-b436-0753b6b51a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载输入信息\n",
    "\n",
    "def read_scores(score_file_path):\n",
    "    # 读全部牙的序号和评分\n",
    "    indices = []\n",
    "    scores = []\n",
    "    with open(score_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            index, score = line.strip().split()\n",
    "            indices.append(int(index))\n",
    "            scores.append(float(score))\n",
    "    return indices, scores\n",
    "\n",
    "def read_obj_file(obj_file_path):\n",
    "    # 读单颗牙的3D模型\n",
    "    points = []\n",
    "    with open(obj_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('v '):\n",
    "                _, x, y, z = line.strip().split()\n",
    "                points.append([float(x), float(y), float(z)])\n",
    "    return np.array(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dca99fd-7780-40c3-8083-610f6a63a40d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Abstraction模块，用于提取点云的局部特征\n",
    "\n",
    "def sampling_layer(points, npoints):\n",
    "    '''\n",
    "    最远点采样 Farthest Point Sample，通过“让采样点之间的最小距离最大化”来用尽可能少的点代表尽可能多的特征。\n",
    "    \n",
    "    算法是：\n",
    "        （1）先随机选取一个点，计算其余点到这个点的距离，选取距离最大的点做第二个点；\n",
    "        （2）已采样N个点时，计算所有剩余点到每个已采样点的距离，对单个剩余点总有一个已采样点在采样点中距离此剩余点最近，取前述最近距离最大的剩余点做为第N+1个采样点；\n",
    "        （3）重复此过程直至达到采样数目要求。\n",
    "    \n",
    "    输入是：\n",
    "        点云（每个点的前三个维度是其空间坐标，其余维度是特征）、采样数。\n",
    "    输出是：\n",
    "        采样出的点云（空间坐标维度+特征维度）。\n",
    "    '''\n",
    "    # 确认点数和采样数\n",
    "    N, D = points.shape\n",
    "    if npoints > N:\n",
    "        # 如果采样点数设置得比点云点数还大，自动报错\n",
    "        raise ValueError(\"npoints should be less than or equal to the number of points in the point cloud\")\n",
    "\n",
    "    # 初始化返回的采样点数组\n",
    "    sampled_points = np.zeros((npoints, D))\n",
    "    \n",
    "    # 初始化距离数组，设置为一个较大的数值\n",
    "    distances = np.ones(N) * 1e10\n",
    "    \n",
    "    # 随机选择第一个点\n",
    "    first_point_index = np.random.randint(0, N)\n",
    "    sampled_points[0] = points[first_point_index]\n",
    "    \n",
    "    # 更新所有点到第一个采样点的距离\n",
    "    for i in range(N):\n",
    "        distances[i] = np.linalg.norm(points[i, :3] - points[first_point_index, :3])\n",
    "    \n",
    "    for i in range(1, npoints):\n",
    "        # 选择距离当前所有采样点最远的点\n",
    "        farthest_point_index = np.argmax(distances)\n",
    "        sampled_points[i] = points[farthest_point_index]\n",
    "        \n",
    "        # 更新所有点到新加入的采样点的距离\n",
    "        for j in range(N):\n",
    "            dist = np.linalg.norm(points[j, :3] - points[farthest_point_index, :3])\n",
    "            if dist < distances[j]:\n",
    "                distances[j] = dist\n",
    "    \n",
    "    return sampled_points\n",
    "\n",
    "\n",
    "def grouping_layer(sampled_points, all_points, R, K):\n",
    "    '''\n",
    "    Ball query，以FPS采样结果的每个点为球心，找到采样前总点云中距离每个球心最近的K个点（含球心），以便在后续步骤中提取局部特征。\n",
    "    \n",
    "    算法是：\n",
    "        （1）预设搜索区域的半径R与子区域的点数K；\n",
    "        （2）FPS采样函数已经提取出来了N'个点，以这N'个点为球心，画半径为R的球体（叫做query ball，也就是搜索区域）；\n",
    "        （3）以每个样本点为球心，按照给定搜索半径R得到一个球形搜索区域，然后从该区域提取前K个最邻近点。如果搜索区域内点数不够，则重复采样；\n",
    "        （4）得到N'个采样点各自对应的包含K个点的子区域，这是一个N'*K*（空间维度+特征维度）的点云。\n",
    "    \n",
    "    输入是：\n",
    "        FPS采样前的点云、FPS采样后的点云、搜索半径R、子区域点数K。\n",
    "    输出是：\n",
    "        N'个采样点各自对应的包含K个点的子区域点云。\n",
    "    '''\n",
    "    # 读输入点云形状\n",
    "    N_prime, D = sampled_points.shape\n",
    "    N, _ = all_points.shape\n",
    "\n",
    "    # 初始化返回的子区域点云数组\n",
    "    local_regions = np.zeros((N_prime, K, D))\n",
    "\n",
    "    for i in range(N_prime):\n",
    "        center_point = sampled_points[i]\n",
    "        \n",
    "        # 计算所有点到球心的距离\n",
    "        distances = np.linalg.norm(all_points[:, :3] - center_point[:3], axis=1)\n",
    "        \n",
    "        # 找到半径R内的点的索引\n",
    "        within_radius_indices = np.where(distances <= R)[0]\n",
    "        \n",
    "        # 如果点的数量少于K个，则随机采样补充至K个\n",
    "        if len(within_radius_indices) < K:\n",
    "            additional_samples = np.random.choice(within_radius_indices, K - len(within_radius_indices), replace=True)\n",
    "            nearest_indices = np.concatenate((within_radius_indices, additional_samples))\n",
    "            nearest_indices = nearest_indices[np.argsort(distances[nearest_indices])]\n",
    "        else:\n",
    "            # 找到距离最近的K个点的索引\n",
    "            nearest_indices = within_radius_indices[np.argsort(distances[within_radius_indices])[:K]]\n",
    "        \n",
    "        # 保存该球心的局部区域点云\n",
    "        local_regions[i] = all_points[nearest_indices]\n",
    "    \n",
    "    return local_regions\n",
    "    \n",
    "\n",
    "def pointnet_layer(local_regions, mlp):\n",
    "    '''\n",
    "    PointNet卷积层，用卷积对采样点进行局部特征提取。\n",
    "    \n",
    "    算法是：\n",
    "        多层感知机（MLP）* 1维卷积。\n",
    "    \n",
    "    输入是：\n",
    "        Ball query得到的N'个采样点各自对应的包含K个点的子区域点云。\n",
    "    输出是：\n",
    "        包含新特征的点云（形状是N'*(3+新特征数量)）\n",
    "    '''\n",
    "    N,K,D = local_regions.shape\n",
    "    reshape_points = local_regions.reshape(N, K * D)\n",
    "    \n",
    "    # 用1维卷积做特征提取\n",
    "    # 1维卷积只能将同一点的不同特征做混合，不同点相对位置引起的特征是靠对点云的采样和分组实现的\n",
    "    new_points = tf.convert_to_tensor(reshape_points, dtype=tf.float32)  # 确保输入是Tensor\n",
    "    new_points = tf.expand_dims(new_points, axis=0)  # 在最外层增加一个batch维度以适应Conv1D\n",
    "    \n",
    "    for out_channel in mlp:\n",
    "        new_points = layers.Conv1D(out_channel, 1, activation='relu')(new_points)\n",
    "        new_points = tf.squeeze(new_points, axis=0)  # 去除多余的维度\n",
    "        new_points = new_points.numpy()  # 将结果转换为NumPy数组以进行连接操作\n",
    "        new_points = np.concatenate((reshape_points[:, :3], new_points), axis=1)\n",
    "        new_points = tf.convert_to_tensor(new_points, dtype=tf.float32)  # 转换回Tensor以进行下一次卷积\n",
    "        new_points = tf.expand_dims(new_points, axis=0)  # 再次增加一个维度以适应下一次Conv1D\n",
    "    \n",
    "    new_points = tf.squeeze(new_points, axis=0).numpy()  # 最后一次去除多余的维度并转换为NumPy数组\n",
    "    \n",
    "    return new_points\n",
    "\n",
    "\n",
    "def SA_module(points, npoints, mlp):\n",
    "    '''\n",
    "    完整的Set Abstraction模块，由Sampling层、Grouping层、PointNet层串联组成。\n",
    "    '''\n",
    "    sampled_points = sampling_layer(points, npoints)\n",
    "    local_regions = grouping_layer(sampled_points, points, R=0.5, K=5)\n",
    "    new_points = pointnet_layer(local_regions, mlp)\n",
    "    \n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c68163-654a-4a68-ad75-1c5d2c8a6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras建模一定有batch维度，但之前的函数没有，需要修改\n",
    "\n",
    "def build_pointnetplusplus(input_shape):\n",
    "    '''\n",
    "    PointNet++模型，需要调用SA模块\n",
    "    输入为“单颗牙的3D模型在采样后的数据格式”，即num_samples*3\n",
    "    输出为训练好的模型\n",
    "    '''\n",
    "    #输入层\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    l0_points = inputs\n",
    "    \n",
    "    # 三个SA模块\n",
    "    l1_points = SA_module(l0_points, npoints=512, mlp=[64, 64, 128])\n",
    "    l2_points = SA_module(l1_points, npoints=256, mlp=[128, 128, 256])\n",
    "    l3_points = SA_module(l2_points, npoints=128, mlp=[256, 512, 1024])\n",
    "    \n",
    "    # 全局最大池化层，用于压缩数据量，也实现了数据扁平化\n",
    "    x = layers.GlobalMaxPooling1D()(l3_points)\n",
    "    \n",
    "    # 全连接层和Dropout层，前者用于进行特征的整合和最终的输出，后者用于减少神经网络的过拟合\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # 输出层\n",
    "    outputs = layers.Dense(1)(x)\n",
    "    \n",
    "    # 构建模型\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    '''\n",
    "    编译模型：\n",
    "    Adam优化器用于加快训练\n",
    "    均方误差Mean Squared Error作为损失函数\n",
    "    平均绝对误差Mean Absolute Error作为评价指标\n",
    "    '''\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e015aa79-b4b3-420e-9e11-eacc10ca85fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_1>',)\n  • kwargs={'mask': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m Vertices_train, Vertices_test, Scores_train, Scores_test \u001b[38;5;241m=\u001b[39m train_test_split(Vertices, Scores, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_pointnetplusplus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(Vertices_train, Scores_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(Vertices_test, Scores_test))\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mbuild_pointnetplusplus\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     20\u001b[0m l0_points \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 三个SA模块\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m l1_points \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSA_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml0_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m l2_points \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: SA_module(x, npoints\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, mlp\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m]))(l1_points)\n\u001b[1;32m     25\u001b[0m l3_points \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: SA_module(x, npoints\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, mlp\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1024\u001b[39m]))(l2_points)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/src/layers/core/lambda_layer.py:95\u001b[0m, in \u001b[0;36mLambda.compute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mshape, output_spec)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe could not automatically infer the shape of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe Lambda\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms output. Please specify the `output_shape` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument for this Lambda layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape(input_shape)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 1024, 3), dtype=float32, sparse=None, name=keras_tensor_1>',)\n  • kwargs={'mask': 'None'}"
     ]
    }
   ],
   "source": [
    "def sample_points(points, num_samples):\n",
    "    # 采样\n",
    "    # 由于每颗牙的3D模型顶点数不同（约2100+），不方便直接用作神经网络的输入，需要统一输入的格式\n",
    "    # 如果某颗牙的顶点数大于采样点数，则采样不可重复，否则采样可重复\n",
    "    # 为了和vertices做变量名上的区分，这个函数中使用了points这个变量名，但实际上就是vertices的数据\n",
    "    # 此处使用的是点云模型，如果用体素模型则有其他的配套手段\n",
    "    if len(points) >= num_samples:\n",
    "        sampled_points = points[np.random.choice(len(points), num_samples, replace=False)]\n",
    "    else:\n",
    "        sampled_points = points[np.random.choice(len(points), num_samples, replace=True)]\n",
    "    return sampled_points\n",
    "\n",
    "\n",
    "# 读序号和评分\n",
    "'''此处为text文件地址，应当改为：’文件夹路径 + scores.txt'''\n",
    "score_file_path = 'scores.txt'\n",
    "indices, scores = read_scores(score_file_path)\n",
    "\n",
    "# 读3D模型，并完成采样\n",
    "'''设置采样点数为1024，可修改'''\n",
    "num_samples = 1024  \n",
    "Vertices = []\n",
    "for i in indices:\n",
    "    obj_file_path = f'{i}.obj'  # 此处为obj文件地址，应当改为：f’ + 文件夹路径 + {i}.obj\n",
    "    points = read_obj_file(obj_file_path)\n",
    "    sampled_points = sample_points(points, num_samples)\n",
    "    Vertices.append(sampled_points)\n",
    "Vertices = np.array(Vertices)\n",
    "Scores = np.array(scores)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "'''此处用的4：1随机分配，以后可以改成k折'''\n",
    "Vertices_train, Vertices_test, Scores_train, Scores_test = train_test_split(Vertices, Scores, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 训练\n",
    "model = build_pointnetplusplus((num_samples, 3))\n",
    "history = model.fit(Vertices_train, Scores_train, epochs=2, batch_size=8, validation_data=(Vertices_test, Scores_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85094d4-e57d-452b-b722-471d9f387ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型评价\n",
    "loss, mae = model.evaluate(Vertices_test, Scores_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6eb852-b8fc-495e-bbff-058de20af291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "model.save('saved_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92adad35-4557-4ff9-bacb-6f5cc86aeb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "loaded_model = tf.keras.models.load_model('saved_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0168a1-93d1-4a76-b230-7597555f2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(new_obj_file_path):\n",
    "    # 读取并预处理新OBJ文件\n",
    "    new_vertices = read_obj_file(new_obj_file_path)\n",
    "    new_sampled_points = sample_points(new_vertices, num_samples)\n",
    "    new_sampled_points = np.expand_dims(new_sampled_points, axis=0)  # 添加批次维度\n",
    "    \n",
    "    # 使用加载的模型进行预测\n",
    "    predicted_score = loaded_model.predict(new_sampled_points)\n",
    "    # print(\"Predicted Score:\", predicted_score[0])\n",
    "    \n",
    "    return predicted_score\n",
    "\n",
    "evaluate_result = {}\n",
    "for i in range(150):\n",
    "    new_obj_file_path = f'{i+1}.obj'  # 待评价对象的地址\n",
    "    evaluate_result[i] = evaluate(new_obj_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9f2d5-7593-4857-b4b5-6cbb2a973558",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd1d81-822a-48b2-9d24-536bbcf382eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccadff4-708c-4727-bdad-8fe88c0d5dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3d008-9f37-4ff7-99b2-bf2a0b11a6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd440d8-fa27-49a3-a5f9-68aab806038c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9edfd81-22e3-4709-b92b-2724645a01af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faa193b-dcd3-40a1-b567-75b4591d57f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0421d3-fb2e-4a64-bdfd-17c03519e206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
